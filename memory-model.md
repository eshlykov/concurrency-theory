## Модель памяти Sequential Consistency для DRF программ

### Введение

Ожидания: память работает атомарно, существует глобальный порядок всех операций. Мы этим пользовались для доказательства корректности мьютекса Петерсона. Другой пример — инварианты в мелкогранулярных блокировках.

Естественно, это все неправда. Иначе не существует никакой параллельности. 

Дело в том, что программа, которую мы пишем, отличается от той, которая исполняется. Мы пишем: `a = 1; b = a + 1` и думаем, что первое раньше второго. «Потому что точка с запятой!»

Однако компилятору на это все равно. Он имеет право менять порядок инструкций в программе, если при этом _не ломатеся логика однопоточной программы_. Это требуется для оптимизации. Но не многопоточной. Но в многопоточных программах порядок бывает критичен. Кроме того, есть реордеринги в процессоре.

Потоки в процессоре могут _наблюдать_ разные истории записи в общую память. Память неатомарна. Например, возможно, что после исполнения следующей программы (классический пример _Independent Reads of Independent Writes, IRIW_) будет получен исход `x = y = 0` (изначально `x = y = 0`):

| Поток 1 | Поток 2 |
|---------|---------|
| `a = 1` | `b = 1` |
| `x = b` | `y = a` |

Так произошло, потому что поток 2 _увидел_ запись в потоке 1 в обратном порядке, а поток 1 увидел запись в потоке 2 в «правильном» порядке: `y = a → a = 1 → x = b → b = 1`.

Архитектура x86 допускает только один вид реордерингов: `load` может обогнать `store`, если они обращаются к разным ячейкам памяти. На других архитектурах все сложнее.

### Модель памяти

Модель (консистентности) памяти – это набор правил, который регламентирует взаимодействие многопоточной программы с разделяемой памятью. Модель памяти отвечает на вопросы:
1. в каком относительном порядке происходят обращения к памяти (чтения и записи) из разных потоков?
2. какое значение прочитает произвольное чтение в программе?

Два аспекта – ordering и visibility.

Главный практический вопрос, на который отвечает модель памяти: _как гарантировать, что запись в память в одном потоке будет доступна чтению в другом потоке_?

#### Hardware Memory Model

* Чаще всего сложная и неинтуитивная.
* Не всегда хорошо документирована.
* Своя для каждой архитектуры.
* В ней очень сложно проводить формальные доказательства и строить инварианты.
* Зато позволяет процессору выполнять программу быстрее (и не важно, что при этом происходит с программой…).

Не годится.

#### Sequential Consistency

_Результат любого исполнения программы такой же, как при некотором последовательном исполнении операций, в котором операции каждого потока исполнялись бы в соответствии с их порядком в программе_

Что значит «такой же»? Наблюдать мы можем только результаты чтений. _Гарантируется, что все чтения вернут тот же результат, что и при некотором последовательном исполнении._

Можно исполнять программу не совсем последовательно, что-то переупорядочивать, лишь бы результат совпадал с результатом некоторого последовательного исполнения. То есть мы можем что-то переупорядочивать так, чтобы исполнение не отличалось от последовательного. Такие исполнения называют _последовательно согласованными_.

Но _последовательно согласованное_ исполнение не есть _последовательное_ исполнение. Последовательная согласованность позволяет моделировать исполнения программы с помощью _модели чередования потоков на единственном процессоре_. Так можно забыть о параллельности и считать все последовательным. Этого достаточно для доказательства наших утверждений.

Но, к сожалению, такого нельзя гарантировать для всех программ (это дорого).

#### Sequential Consistency for Data-Race-Free Programs

Новое соглашение: гарантируем последовательно согласованные исполнения только для программ без гонок. _Если в программе нет гонок (data-race-free), то результат ее исполнения не будет отличаться от некоторого последовательного исполнения._

SC-DRF — контракт между программистом и производителем процессора / разработчиком компилятора:
* программист обязуется написать корректно синхронизированную (в рамках модели) программу;
* компилятор и процессор обещают выполнить эту программу так, чтобы программист не смог отличить исполнение от последовательного.

Контракт фиксируется в стандарте языка программирования в виде модели памяти. Реализуют контракт разработчики компилятора и процессора.
* Разработчики процессора описывают правила упорядочивания обращений к памяти и предоставляют специальные инструкции, с помощью которых можно влиять на порядок — барьеры памяти.
* Компилятор расставляет эти барьеры в коде, полагаясь на корректность программы.

Например, модель памяти появилась в Java в 2002 году (она очень сложная, зато работает), в C++ — только с выходом стандарта C++11 (она достаточно простая).

Какие минимальные гарантии упорядочивания нужно обеспечить при исполнении программы, чтобы:
* программист не смог отличить исполнение от последовательного;
* процессор мог бы выполнять разные оптимизации?

Цели противоположные: с одной стороны, обеспечить порядок, с другой – уйти от жесткого порядка.

### Изучаем Sequential Consistency

Перед нами программа, в которой несколько потоков и много обращений к памяти. Для простоты – только чтения и записи. Попытаемся понять, для каких обращений к памяти нужен жесткий порядок исполнения, а для каких — нет.

Два обращения к памяти конфликтуют, если:
* они обращаются к одной и той же ячейке памяти;
* по крайней мере одно из этих обращений — запись.

Ситуацию, когда конфликтующие обращения к памяти конкурируют друг с другом, будем называть гонкой.

Гонки не являются чем-то плохим. В них сама суть синхронизации. Например, в мьютексе Петерсона гонки на записи в `victim_` и запись и чтение `want[]`. Подобные обращения к памяти необходимо глобально упорядочить, иначе мы не сможем реализовать мьютекс!

Выделим подмножество переменных, которые используются для синхронизации, и назовем их _атомиками_, а обращения к этим переменным – synchronization actions. Программист должен сам аннотировать эти переменные:
* _(C++)_ `std::atomic<T>`, `std::memory_order_seq_cst`;
* _(Java)_ `volatile`.

Для них требуем последовательного исполнения. Оно не должно противоречить порядку инструкций.

Обращения ко всем остальным переменным назовем data actions. Они не требуют последовательного обращения. Нужно лишь гарантировать, что чтения, которые зависят по логике программы от каких-либо записей, увидят результат этих записей.

#### Порядок обращений к памяти

Для атомарных переменных при исполнении гарантируется глобальный порядок всех обращений к памяти — synchronization order. Каждое чтение в этом порядке читает результат последней предшествующей записи. Он должен быть согласован c порядком инструкций program-order.

Порядок synchronization order может отличаться от запуска к запуску и в общем случае заранее неизвестен (например, в мьютексе Петерсона мы не можем знать, какой из потоков последним запишет `victim_` и проиграет).

Но важно здесь, что исполнение объясняется некоторым глобальным порядком.

Для неатомарных обращений к памяти все чуть сложнее: глобального порядка модель памяти не обещает, зато дает гарантии видимости записей:
* в пределах одного потока модель памяти гарантирует видимость записей в последующих чтениях через отношение program-order, которое соответствует порядку инструкций в тексте программы;
* запись в одном потоке становится видимой для чтений в другом потоке, только когда между потоками возникает «мост» - стрелка synchronizes-with, по этому мосту записи «переходят» в другие потоки.

  Пусть `a` и `b` – два synchronization actions: `a` – запись в некоторую ячейку `x`, `b` – чтение из этой ячейки в другом потоке. `a sw→ b`, если чтение `b` прочитало значение, записанное записью `a`.

  Стрелка `sw→` возникает или не возникает в зависимости от исполнения. Фактически, `sw→` определяется отношением `so→`.

  `po→` и `sw→` — отношения частичного порядка на обращениях к памяти. Отношение `po→` — статическое, определяется лишь текстом программы и известно на этапе компиляции. Отношение `sw→` — динамическое, возникает только на этапе исполнения программы!

  Дальше неатомарные записи «растекаются» по транзитивности, двигаясь по стрелкам program-order и synchronizes-with и становятся доступными для чтений.

* Транзитивное замыкание program-order и synchronizes-with образует частичный порядок happens-before.

Описанные гарантии работают только в случае, когда в программе нет гонок. Гонкой называются два конфликтующих обращения к памяти, которые не упорядочиваются во время исполнения отношением happens-before.

#### Видимость

Что может вернуть чтение?

На атомиках чтение возвращает результат _последней записи_. _Последней — в линейном порядке `so→`_.

Для неатомиков чтение возвращает значение, записанное _последней записью, предшествующей этому чтению в порядке `hb→`_.

Что будет, если в одно чтение ведут несколько цепочек `hb→`? Ответ: это гонка, такие программы запрещены. Формальное определение гонки:
* два обращения к памяти конфликтуют, если они обращаются к одной ячейке и по крайней мере одно из этих обращений — запись.
* гонкой по данным (_data race_) называют два конфликтующих data actions, которые не упорядочены отношением `hb→`.

Мы запрещаем программы с гонками на data actions.

Если гонок нет, то все конфликтующие обращения к каждой неатомарной переменной провязаны в цепочку `hb→`. Иначе говоря, по логике программы все обращения к переменной происходят упорядоченно. Программа просит упорядочить все обращения к атомикам, а дальше сама должна упорядочить остальные обращения к памяти.

#### Последовательная согласованность

Наша модель гарантирует:
* линейный порядок для synchronization actions — `so→`.
 Чтение возвращает последнюю предшествующую запись в порядке `so→`;
* Видимость записей через частичный порядок `hb→` для data actions.
 Чтение возвращает последнюю предшествующую запись в порядке `hb→`

Программа при этом обещает, что в ней нет гонок.

Формула модели памяти: линейный порядок на атомиках + видимость через `hb→` + нет гонок на data actions.

Почему это дает последовательную согласованность?

Модель памяти гарантирует видимость записей через отношения частичного порядка `hb→` и `so→`. Оба этих порядка согласованы с `po→` и не противоречат друг другу.

##### Теорема
> `hb→` и `so→` можно достроить до линейного порядка `T→`: `(︁hb→ ∪ so→)︁ ⊂ T→` — который согласован с порядком инструкций в тексте программы и в котором каждое чтение видит значение, записанное последней предшествующей в `T→` записью.

###### Доказательство

`T→` – кандидат на эквивалентное последовательное исполнение. Достаточно, очевидно, что оно существует: `sw→` образуются только от `so→`, `so→` соблюдает `po→`, они не дают циклов, поэтому транзитивное замыкание `hb→` также не содержит циклов. Значит, можно сделать топологическую сортировку.

Докажем вторую часть утверждения. Возьмем произвольное чтение `r` из `T→` и покажем, что оно возвращает результат последней предшествующей записи в `T→`. Сам факт предшествования в `T→` пока ничего не означает, видимость записей гарантируется через `so→` и `hb→`.

Для атомиков это свойство тривиально выполняется, так как все обращения к атомикам упорядочены через `so→`, а `T→` является продолжением `so→`.

Если чтение `r` — не атомарное, тогда оно читает результат последней записи в цепочке `hb→`, обозначим эту запись через `w`. Запись `w hb→ r`, а значит `w T→ r`.

От противного: пусть найдется запись `w'`, которая находится между `w` и `r` в `T`, то есть имеем `w T→ w' T→ r`. Так как `hb→ ⊂ T→`, то `w' hb⇸ w`. Две конфликтующие записи должны быть упорядочены (нет гонок), `w hb→ w'`. Аналогично `w' hb→ r`. Таким образом, `w hb→ w' hb→ r` — противоречие с тем, что `r` прочитало результат записи `w`.

Теорема доказана.

Из исполнения в нашей модели получили линейный порядок `T→`:
* который согласован с порядком инструкций в тексте программы,
* в котором каждое чтение видит значение, записанное последней предшествующей в `T→` записью.

Таким образом, исполнение последовательно согласовано, неотличимо от некоторого последовательного исполнения `T→`.

### Итоги

Чтобы доказать отсутствие гонок в программе, нужно построить все варианты частичного порядка `hb→`. Оказывается, _можно проанализировать только последовательные исполнения и проверить наличие гонок в них_. Если гонок не будет, то модель памяти гарантирует, что любое исполнение будет последовательно согласованным.

Модель памяти SC-DRF гарантирует последовательную согласованность не для всех программ, а только для программ без гонок. Программисту нужно доказывать корректность программы.

Что мы выиграли? Компилятор и процессор получили свободу для оптимизаций!

В программе нет гонок, следовательно поток `T'` не может наблюдать относительный порядок независимых неатомарных записей в потоке `T` между точками синхронизации.

Можем переупорядочить два независимых data actions, если:
* не нарушается логика работы внутри потока;
* не выходим за границы synchronization actions.

Можно провести аналогию с критическими секциями. Если внести операцию внутрь критической секции, то это уменьшит параллельность, но не повлияет на корректность исполнения. Выносить операции из критической секции, разумеется, не стоит.

Обычные обращения к памяти можно переносить через синхронизации: назад через записи, вперед через чтения. Для наблюдателя: `hb→` для исполнения новой программы будет неотличим от `hb→` для некоторого исполнения исходной программы!

Получаем два класса безопасных реордерингов, которые не нарушают иллюзию последовательного исполнения для программ без гонок. Эти оптимизации локальны, они не требуют знания всего графа предшествования `hb→`. А значит их может применять компилятор для отдельных единиц трансляции и процессор прямо на лету исполнения.

### Реализация модели памяти

У программиста есть программа, у процессора — своя модель памяти. Где и как реализована модель памяти языка?

На уровне библиотеки / компилятора — c помощью специальных инструкций — барьеров памяти
(memory barriers / fences). Барьеры позволяют ограничить переупорядочивания и фиксировать записи в памяти.

Точная семантика барьеров и их набор очень сильно зависит от архитектуры процессора, на каждой архитектуре — собственный зоопарк.

### Слабые упорядовчивания

Под ослаблением понимается использование режимов упорядочивания release / acquire и relaxed.

Рассмотрим гарантии, которые дают ослабленные модели упорядочивания.

#### release/acquire

* Теряем глобальный порядок на обращениях к разным атомикам.
* Сохраняем видимость записей через happens-before: если acquire-чтение прочитало результат release-записи, то между ними возникает synchronizes-with.

Такого режима может быть достаточно, если разные потоки синхронизируются через один атомик, а для каждого атомика в отдельности гарантируется единый порядок модификации.

Примеры, когда упорядочивания release/acquire не достаточно:
* IRIW;
* протокол взаимного исключения Петерсона для двух потоков.

Например, в примере IRIW (Independent Reads of Independent Writes) c release / acquire два потока могут увидеть разный порядок записей в две разные ячейки:

| `T_1`   | `T_2`   | `T_3`   | `T_4`   |
|---------|---------|---------|---------|
| `x = 1` | `y = 1` | `a = x` | `c = y` |
|         |         | `b = y` | `d = x` |

Допускается результат: `a = 1`, `b = 0`, `c = 1`, `d = 0`. Иначе говоря, потоки `T_3` и `T_4` видят разный порядок записей в ячейки `x` и `y`.


#### relaxed

relaxed — самый слабый режим упорядочивания, гарантирует только, что все потоки наблюдают единый порядок модификации каждой отдельной ячейки.

При этом разные потоки могут видеть две записи в две разные ячейки в разном порядке, никаких гарантий мы здесь не получаем.

При использовании relaxed между записью и чтением не возникает стрелка synchronizes-with, предшествующие записи не «перетекают» в другие потоки, так что делать выводы о содержимом других ячеек памяти на основе результата relaxed-чтения нельзя.

Фактически, остаются только гарантии того, что операция над ячейкой памяти произойдёт атомарно.

### Замечания

* Доказывая корректность своих программ, не следует рассуждать в терминах барьеров памяти и реордерингов. Эти вещи слишком низкоуровневые, их семантика сильно зависит от конкретной архитектуры процессора. Следует пользоваться формальной моделью и рассуждать в терминах видимости через порядки. Для этого модель памяти и придумали.

* Для обозначения ошибок в многопоточных программах используется два похожих термина: data race и race condition. Это разные ошибки. Примеры race condition:
  * intercepted wakeup в блокирующей очереди;
  * повторное расширение хэш-таблицы разными потоками.

  Возникновение race condition возможно и без data race.
