## Транзакции

Рассмотрим простую модель. У нас есть некоторый _DataStore_ с двумя операциями:
* _Read(k)_ — прочитать по ключу значение;
* _Write(k, v)_ — записать по ключу значение.

**Транзакция** - это маленькая программа, которая начинается со специальной команды `CommitTx` и заканчивается одной из двух команд — `CommitTx` или `AbortTx`. А между этими командами у нас есть чтения и записи плюс какая-то логика, которая управляет этими чтениями и записями.

Транзакция может завершится успешно или неуспешно. `Commit` означает, что все записи, сделанные внутри транзакции, мы хотим применить к хранилищу. Команда `Abort` означает, что сделанные изменения надо откатить.

Когда надо добровольно делать `Abort`? Например, мы хотим перевести деньги с одного счета на другой, но выясняется, что суммы недостаточно. Вообще, транзакция не обязана завершатся успешно, даже если мы сделали `Commit`. Это слуается сплошь и рядом, так как транзакции могут конкурировать друг с другом.

Таким образом, транзакция может отмениться не по причине нарушения каких-то инвариантов, которые мы контролируем, а из-за каких-то деталей внутренней реализации.

### ACID — требования к транзакциям

* A (_atomicity_) — если транзакция отменилась или транзакция выполнялась, а машина рестартовала, то в вашей базе данных от транзакции никаких следов не останется (то есть транзакция применяется либо целиком, либо не применяется вообще);
* C (_consistency_) — это требования, что база данных целиком находится в некотором глобальном согласованном состоянии, то есть в ней выполняются какие-то инварианты (с другой стороны, база данных о них ничего не знает, это инвариант пользователя);
* I (_isolation_) — как ведут себя конкурирующие транзакции, как их выполнение сказывается на базе данных;
* D (_durability_) — после коммита транзакции данные остаются в базе данных навсегда, даже если машины перезапускаются и прочее.

### Scheduler

За изоляцию в базе отвечает специальный компонент, который мы назовем **планировщиком** (scheduler).

Под планировщиком находится хранилище. К планировщику с разных сторон поступаются операции из транзакции (чтения, записи, `StartTx`, `CommitTx`, `AbortTx`).

Задача планировщика брать эти обращения из разных транзакций и перенаправлять их в хранилище, причем требуется, чтобы транзакции выполнялись как будто бы атомарно.

Само хранилище будем считать линеаризуемым.

Планировщик порождает **расписание** (schedule) — последовательность чтений и записей из разных транзакций. Например: _Write(1, x); Write(2, y); Read(1, y)_.

Расписание работает параллельно, но из-за линеаризуемости хранилища можно считать, что получаемые расписания последовательные.

### View-Serializability

Расписание называется **последовательным** (serial), если операции всех транзакций сгруппированы по номеру транзакции.

Расписание называется **view-сериализуемым** (view-serializable), если существует такое последовательное расписание (перестановка операций из исходного расписания), что все чтения возвращают одно и то же.

Нам совершенно неважно, как планировщик перемешал эти операции. Более того, мы это даже не наблюдаем. Но нам важно, что все чтения из хранилища объясняются некоторым последовательным выполнением этих траназакций.

Однако view-сериализуемые расписания могут быть устроены произвольным образом. Например, пусть есть три транзакции:

| _T1_          | _T2_          | _T3_          |
| ------------- | ------------- | ------------- |
| _Write(x, 1)_ |               |               |
|               | _Write(x, 2)_ |               |
|               | _Write(y, 2)_ |               |
| _Write(y, 1)_ |               |               |
|               |               | _Write(y, 3)_ |

До прихода последней транзакции расписания не было view-сериализуемости, но внезапно пришедшая транзакция _T3_ это замаскировала.

Наш планировщик не может предвидеть будущее. Нам нужен какой-то простой детерменированный онлайн-алгоритм, который будет генерировать только хорошие расписания. На приведенный пример он способен не будет, так как не знает, что придет новая транзакция и спасет его.

Вообще, тестирование расписание на сериализуемость — NP-полная задача. Как они устроены, непонятно.

### Conflict-Serializability

Рассмотрим все view-сериализуемые расписания и выделим в нем подкласс, к которому существует простой критерий принадлежности.

Назовем два обращения их двух разных транзакций **конфликтующими**, если они обращаются по одному ключу и хотя бы одно из этих обращений — запись.

Если у нас есть расписание, в котором две операции конфликтуют, то их порядок зафиксирован, мы их не можем поменять местами. А если две операции не конфликтуют, то их можно свопнуть, и никто ничего не заметит, так как на чтение это не повлияет.

Два расписания **конфликтно-эквивалентны** (conflict-equivalent), если одно из них можно перевести в другое серией свопов неконфликтующих операций.

Наконец, расписание называется **конфликтно-сериализуемым** (conflict-serializable), если существует конфликтно-эквивалентное ему последовательное расписание.

Очевидно, конфликтно-сериализуемые расписания являются view-сериализуемыми, поскольку мы явно приводим их к последовательному виду.

Расписисание из примера сериализуемым не является.

### Conflict Graph

Окзывается, мы можем легко проверять, является ли расписание конфликтно-сериализуемым.

Построим **граф конфликтов** (conflict graph, CG) для предложенного расписания. Вершины — это транзакции. Между транзакциями проводится дуга от _T1 к _T2_, если в данном расписании есть два конфликтующих обращения _O1_ и _O2_ из транзакций _T1_ и _T2_ соответственно, причем _O1_ предшествует _O2_.

Если такая пара есть, то их нельзя свопнуть, а значит, транзакция _T1_ должна предшествовать транзакции _T2_.

Критерий конфликтной сериализуемости: расписание является конфликтно-сериализуемым тогда и только тогда, когда графе конфликтов для данного расписания ацикличен.

Предположим, расписание является конфликтно-сериализуеммым, но в графе есть циклов. Тогда серией свопов его можно привести к последовательному виду. Любой своп некофликтующих операций не меняет граф конфликтов, поэтому дуги не появляются и не исчезают. А в последовательном виде циклов точно нет.

Предположим, в графе конфликтов нет циклов. Тогда есть хотя бы одна транзакция с нулевой входящей степенью. Выберем одну из таких транзакций. Посмотрим на любую операцию в этой транзакции. Эта операций необязательно идет первой. Но мы знаем, что никакое из более ранних обращений не конфликтует с данной, потому что в противном случае было бы ребро, то есть входящая степень была бы положительной. Значит, эту операцию можно передвинуть к началу. А дальше повторяем.

Имея такой простой критерий, можно сделать поддерживать граф и просто отменять транзакцию, когда в графе конфликтов возникает цикл.

Но можно сделать лучше: построим алгоритм, который циклов не порождает.

### (Strict) Two-Phase Locking

Начинаем транзакцию. Отправляем планировщику чтение либо запись. Он смотрит на наше чтение либо на нашу запись по некоторому ключу.

Если он видит, что мы к этому ключу раньше не обращались, то планировщик на этот ключ берет блокировку. А дальше читаем либо пишем.

Дальше делаем следующее чтение или запись, и также, если это новый ключ, берем блокировку на него.

Локи отпускаются только после коммита или аборта.

Фаза, на которой мы берем локи, называется Expanding, а фаза, на которой отпускаем локи, называется Shrinking.

Таким образом, локов после анлоков не бывает, первый анлок происходит после последнего лока.

Докажем, что граф конфликтов для всех получаемых расписаний не содержит циклов.

Предположим, что в графе все же возник цикл: _T1_, _T2_, ..., _T1_.

Так как есть дуга из _T1_ в _T2_, то есть два конфликтующих обращения _O1'_ и _O2_, причем _O1'_ предшествует _O2_. Дуга из _T2_ в _T3_ означает, что есть два обращения _O2'_ и _O3_, причем _O2'_ предшествует _O3_. И так далее.

Из постороения алгоритма следует, что _Unlock(O1')_ предшествует _Lock(O2)_. Далее, _Unlock(O2')_ предшествует _Lock(O3)_. Но из-за двухфазности блокировок также _Lock(O2)_ предшествует _Unlock(O2')_.

Наконец, достроим теперь эту цепочку до _Lock(O1)_. Получили, что _Unlock(O1')_ предществует _Lock(O1)_. Алгоритм так сделать не мог.

Таким образом, наш алгоритм генерирует только конфликтно-сериализуемые расписания.

### Решение проблемы с дедлоками

Планировщик не знает, в каком порядке к нему приходят операции. Более того, в самой транзакции может быть условная логика, поэтому нельзя предугадать, в каком порядке будут браться локи.

Поэтому алгоритм 2PL допускает дедлоки.

Решение в лоб — поддерживать явно wait-for graph, но это затратно.

Рассмотрим более изящное решение. Допустим, две транзакции претендуют на один лок. Кто из них его больше заслуживает?

Присвоим каждой транзакции на старте временную метку. Их будет выдавать планировщик, причем монотонно. То есть чем раньше транзакция пришла, тем меньше ее метка.

Итак, если мы старая транзакция, которая видит, что молодая транзакция держит лок, который нам нужен, то можно поабортить молодую транзакцию. Если мы видим, что еще более старая транзакция держит этот лок, то уступим ее и подождем (или поабортимся сами).

После падения мы начинаем транзакцию заново, однако со старой временной меткой. В противном случае мы можем все время абортится, так как наша метка становится все больше и больше.

Здесь можно также брать на чтения _ReadLock_, а на записи _WriteLock_.
